# 🚀 深度学习快速参考卡

## 核心流程
```
数据加载 → 数据清洗 → 特征工程 → 模型定义 → 训练 → 预测 → 保存结果
```

## ⚡ 最重要的10个概念

### 1. 📊 **张量 (Tensor)**
```python
torch.FloatTensor(array)  # numpy数组 → PyTorch张量
```
**作用**: PyTorch的基本数据结构，支持GPU加速和自动求导

### 2. 🏗️ **全连接层 (Linear Layer)**
```python
nn.Linear(输入维度, 输出维度)  # 例: nn.Linear(64, 32)
```
**作用**: 线性变换，output = input × weight + bias

### 3. ⚡ **激活函数 (ReLU)**
```python
nn.ReLU()  # ReLU(x) = max(0, x)
```
**作用**: 引入非线性，让网络能学习复杂模式

### 4. 📏 **标准化 (StandardScaler)**
```python
scaler = StandardScaler()
X = scaler.fit_transform(X)  # 均值0，标准差1
```
**作用**: 让不同尺度的特征在同一量级，提升训练效果

### 5. 📊 **损失函数 (MSELoss)**
```python
criterion = nn.MSELoss()  # 均方误差
loss = criterion(预测值, 真实值)
```
**作用**: 衡量预测值与真实值的差距

### 6. 🎯 **优化器 (Adam)**
```python
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```
**作用**: 根据梯度智能更新网络参数

### 7. 🔄 **训练循环的4步骤**
```python
pred = model(X)           # 1. 前向传播
loss = criterion(pred, y) # 2. 计算损失
optimizer.zero_grad()     # 3a. 清零梯度
loss.backward()          # 3b. 反向传播
optimizer.step()         # 4. 更新参数
```

### 8. 📦 **批处理 (Batch)**
```python
BATCH_SIZE = 64  # 每次处理64个样本
for i in range(0, len(X), BATCH_SIZE):
    batch_X = X[i:i+BATCH_SIZE]
```
**作用**: 分批处理数据，节省内存，提高效率

### 9. 🔀 **模式切换**
```python
model.train()  # 训练模式
model.eval()   # 评估模式
```
**作用**: 训练时启用dropout等，预测时关闭

### 10. 🚫 **禁用梯度**
```python
with torch.no_grad():
    predictions = model(X)
```
**作用**: 预测时不计算梯度，节省内存和计算

---

## 📋 代码中的关键步骤对照

| 代码行 | 作用 | 关键概念 |
|-------|------|----------|
| `pd.read_csv()` | 读取数据 | 数据加载 |
| `replace('-', np.nan)` | 处理缺失值 | 数据清洗 |
| `StandardScaler()` | 数据标准化 | 特征工程 |
| `nn.Sequential()` | 定义网络结构 | 模型构建 |
| `loss.backward()` | 计算梯度 | 反向传播 |
| `optimizer.step()` | 更新参数 | 参数优化 |
| `torch.save()` | 保存模型 | 模型持久化 |

---

## 🎯 理解代码的建议步骤

1. **先看整体流程**: 按步骤1-9的顺序理解
2. **关注关键函数**: 重点理解上面10个核心概念
3. **对比参考文档**: 用《深度学习函数详解.md》查具体用法
4. **动手实验**: 试着修改参数，观察效果
5. **逐步深入**: 从简单概念到复杂概念

## 💡 常见问题

**Q: 为什么要标准化？**
A: 让不同尺度的特征（如年龄1-100，价格1000-50000）在同一量级，避免大数值特征占主导

**Q: ReLU激活函数有什么用？**
A: 引入非线性，没有激活函数的话，多层网络等同于一层

**Q: 为什么要分训练集和验证集？**
A: 验证集用来评估模型真实性能，防止模型"背书"（过拟合）

**Q: 什么是梯度？**
A: 梯度告诉我们参数该往哪个方向调整，调整多少

**Q: 批处理有什么好处？**
A: 节省内存，梯度更稳定，训练更高效