"""
ğŸ“ äº’åŠ¨å­¦ä¹ ç‰ˆ - äºŒæ‰‹è½¦ä»·æ ¼é¢„æµ‹
ä¸€æ­¥ä¸€æ­¥è¿è¡Œï¼Œç†è§£æ¯ä¸ªæ¦‚å¿µ

ä½¿ç”¨æ–¹æ³•ï¼š
1. å–æ¶ˆæ³¨é‡Šæƒ³è¦è¿è¡Œçš„éƒ¨åˆ†ï¼ˆåˆ é™¤ # å·ï¼‰
2. è¿è¡Œä»£ç ï¼Œè§‚å¯Ÿè¾“å‡º
3. é˜…è¯»è§£é‡Šï¼Œç†è§£æ¦‚å¿µ
4. ç»§ç»­ä¸‹ä¸€éƒ¨åˆ†
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

print("ğŸ“ æ¬¢è¿æ¥åˆ°æ·±åº¦å­¦ä¹ äº’åŠ¨æ•™ç¨‹ï¼")
print("è¯·æŒ‰æ­¥éª¤å–æ¶ˆæ³¨é‡Šå¹¶è¿è¡Œä»£ç ")

# ============================================================================
# ğŸ” ç¬¬ä¸€æ­¥ï¼šäº†è§£æ•°æ®
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

print("\nğŸ” ç¬¬ä¸€æ­¥ï¼šäº†è§£æ•°æ®")
train_data = pd.read_csv("used_car/used_car_train.csv")

# æŸ¥çœ‹æ•°æ®åŸºæœ¬ä¿¡æ¯
print(f"æ•°æ®å½¢çŠ¶: {train_data.shape}")
print(f"åˆ—å: {list(train_data.columns)}")
print("\nå‰5è¡Œæ•°æ®:")
print(train_data.head())

# æŸ¥çœ‹æ•°æ®ç±»å‹
print(f"\næ•°æ®ç±»å‹:")
print(train_data.dtypes)

# æŸ¥çœ‹ç¼ºå¤±å€¼æƒ…å†µ
print(f"\nç¼ºå¤±å€¼ç»Ÿè®¡:")
missing = train_data.isnull().sum()
print(missing[missing > 0])

# ğŸ’¡ è§£é‡Šï¼š
# - shape: (è¡Œæ•°, åˆ—æ•°)
# - head(): æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
# - dtypes: æ¯åˆ—çš„æ•°æ®ç±»å‹
# - isnull().sum(): ç»Ÿè®¡æ¯åˆ—çš„ç¼ºå¤±å€¼æ•°é‡

# ============================================================================
# ğŸ§¹ ç¬¬äºŒæ­¥ï¼šæ•°æ®æ¸…æ´—å®éªŒ
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nğŸ§¹ ç¬¬äºŒæ­¥ï¼šæ•°æ®æ¸…æ´—å®éªŒ")

# # åˆ›å»ºä¸€ä¸ªå°ä¾‹å­æ¥ç†è§£æ•°æ®æ¸…æ´—
# sample_data = pd.DataFrame({
#     'feature1': [1, 2, '-', 4, 5],
#     'feature2': [10, '-', 30, 40, 50],
#     'price': [1000, 2000, 1500, 3000, 2500]
# })

# print("åŸå§‹æ•°æ®:")
# print(sample_data)

# # æ›¿æ¢ '-' ä¸º NaN
# sample_cleaned = sample_data.replace('-', np.nan)
# print("\næ›¿æ¢'-'ä¸ºNaNå:")
# print(sample_cleaned)

# # è½¬æ¢æ•°æ®ç±»å‹
# numeric_data = sample_cleaned.astype(float, errors='ignore')
# print(f"\nè½¬æ¢ä¸ºæ•°å€¼ç±»å‹å:")
# print(numeric_data)

# # å¤„ç†ç¼ºå¤±å€¼
# filled_data = numeric_data.fillna(0)
# print(f"\nç”¨0å¡«å……ç¼ºå¤±å€¼å:")
# print(filled_data)

# ğŸ’¡ è§£é‡Šï¼š
# - replace(): æ›¿æ¢ç‰¹å®šå€¼
# - astype(): è½¬æ¢æ•°æ®ç±»å‹
# - fillna(): å¡«å……ç¼ºå¤±å€¼

# ============================================================================
# ğŸ“ ç¬¬ä¸‰æ­¥ï¼šæ ‡å‡†åŒ–å®éªŒ
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nğŸ“ ç¬¬ä¸‰æ­¥ï¼šæ ‡å‡†åŒ–å®éªŒ")

# # åˆ›å»ºç¤ºä¾‹æ•°æ®ï¼ˆä¸åŒå°ºåº¦ï¼‰
# data = np.array([
#     [1, 1000],      # å¹´é¾„, ä»·æ ¼
#     [5, 5000],
#     [10, 10000],
#     [2, 2000]
# ])

# print("åŸå§‹æ•°æ®ï¼ˆå¹´é¾„ vs ä»·æ ¼ï¼‰:")
# print(data)
# print(f"å‡å€¼: {data.mean(axis=0)}")
# print(f"æ ‡å‡†å·®: {data.std(axis=0)}")

# # æ ‡å‡†åŒ–
# scaler = StandardScaler()
# standardized = scaler.fit_transform(data)

# print(f"\næ ‡å‡†åŒ–å:")
# print(standardized)
# print(f"å‡å€¼: {standardized.mean(axis=0)}")
# print(f"æ ‡å‡†å·®: {standardized.std(axis=0)}")

# ğŸ’¡ è§£é‡Šï¼š
# - æ ‡å‡†åŒ–è®©æ‰€æœ‰ç‰¹å¾éƒ½å˜æˆå‡å€¼0ã€æ ‡å‡†å·®1
# - è¿™æ ·ä¸åŒå°ºåº¦çš„ç‰¹å¾å°±åœ¨åŒä¸€é‡çº§äº†

# ============================================================================
# âš¡ ç¬¬å››æ­¥ï¼šå¼ é‡å®éªŒ
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nâš¡ ç¬¬å››æ­¥ï¼šå¼ é‡å®éªŒ")

# # NumPyæ•°ç»„
# np_array = np.array([1, 2, 3, 4, 5], dtype=np.float32)
# print(f"NumPyæ•°ç»„: {np_array}")
# print(f"ç±»å‹: {type(np_array)}")

# # è½¬æ¢ä¸ºPyTorchå¼ é‡
# tensor = torch.FloatTensor(np_array)
# print(f"\nPyTorchå¼ é‡: {tensor}")
# print(f"ç±»å‹: {type(tensor)}")
# print(f"å½¢çŠ¶: {tensor.shape}")

# # å¼ é‡è¿ç®—
# tensor_squared = tensor ** 2
# print(f"\nå¼ é‡å¹³æ–¹: {tensor_squared}")

# # è½¬æ¢å›NumPy
# back_to_numpy = tensor.numpy()
# print(f"\nè½¬æ¢å›NumPy: {back_to_numpy}")

# ğŸ’¡ è§£é‡Šï¼š
# - å¼ é‡æ˜¯PyTorchçš„åŸºæœ¬æ•°æ®ç»“æ„
# - æ”¯æŒGPUåŠ é€Ÿå’Œè‡ªåŠ¨æ±‚å¯¼
# - å¯ä»¥ä¸NumPyäº’ç›¸è½¬æ¢

# ============================================================================
# ğŸ—ï¸ ç¬¬äº”æ­¥ï¼šç®€å•ç½‘ç»œå®éªŒ
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nğŸ—ï¸ ç¬¬äº”æ­¥ï¼šç®€å•ç½‘ç»œå®éªŒ")

# # å®šä¹‰ä¸€ä¸ªè¶…ç®€å•çš„ç½‘ç»œ
# class TinyModel(nn.Module):
#     def __init__(self):
#         super(TinyModel, self).__init__()
#         self.layer = nn.Linear(2, 1)  # 2ä¸ªè¾“å…¥ -> 1ä¸ªè¾“å‡º

#     def forward(self, x):
#         return self.layer(x)

# # åˆ›å»ºæ¨¡å‹
# tiny_model = TinyModel()
# print(f"æ¨¡å‹ç»“æ„:")
# print(tiny_model)

# # åˆ›å»ºç¤ºä¾‹è¾“å…¥
# sample_input = torch.FloatTensor([[1.0, 2.0], [3.0, 4.0]])
# print(f"\nè¾“å…¥æ•°æ®:")
# print(sample_input)

# # å‰å‘ä¼ æ’­
# output = tiny_model(sample_input)
# print(f"\nè¾“å‡ºç»“æœ:")
# print(output)

# # æŸ¥çœ‹å‚æ•°
# print(f"\nç½‘ç»œå‚æ•°:")
# for name, param in tiny_model.named_parameters():
#     print(f"{name}: {param.data}")

# ğŸ’¡ è§£é‡Šï¼š
# - nn.Linear(): å…¨è¿æ¥å±‚ï¼Œè¿›è¡Œçº¿æ€§å˜æ¢
# - forward(): å®šä¹‰æ•°æ®æµå‘
# - parameters(): ç½‘ç»œçš„å¯å­¦ä¹ å‚æ•°

# ============================================================================
# ğŸ¯ ç¬¬å…­æ­¥ï¼šæŸå¤±å‡½æ•°å®éªŒ
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nğŸ¯ ç¬¬å…­æ­¥ï¼šæŸå¤±å‡½æ•°å®éªŒ")

# # åˆ›å»ºé¢„æµ‹å€¼å’ŒçœŸå®å€¼
# predictions = torch.FloatTensor([2.5, 3.1, 1.8])
# true_values = torch.FloatTensor([2.0, 3.0, 2.0])

# print(f"é¢„æµ‹å€¼: {predictions}")
# print(f"çœŸå®å€¼: {true_values}")

# # è®¡ç®—MSEæŸå¤±
# mse_loss = nn.MSELoss()
# loss = mse_loss(predictions, true_values)

# print(f"\nMSEæŸå¤±: {loss.item():.4f}")

# # æ‰‹åŠ¨è®¡ç®—éªŒè¯
# manual_mse = ((predictions - true_values) ** 2).mean()
# print(f"æ‰‹åŠ¨è®¡ç®—MSE: {manual_mse.item():.4f}")

# ğŸ’¡ è§£é‡Šï¼š
# - MSE = (é¢„æµ‹å€¼-çœŸå®å€¼)Â²çš„å¹³å‡å€¼
# - æŸå¤±è¶Šå°ï¼Œæ¨¡å‹é¢„æµ‹è¶Šå‡†ç¡®

# ============================================================================
# ğŸ”„ ç¬¬ä¸ƒæ­¥ï¼šç®€å•è®­ç»ƒå¾ªç¯
# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥è¿è¡Œè¿™éƒ¨åˆ†
# ============================================================================

# print("\nğŸ”„ ç¬¬ä¸ƒæ­¥ï¼šç®€å•è®­ç»ƒå¾ªç¯")

# # åˆ›å»ºç®€å•çš„è®­ç»ƒæ•°æ®
# X = torch.FloatTensor([[1], [2], [3], [4]])  # è¾“å…¥
# y = torch.FloatTensor([2, 4, 6, 8])          # ç›®æ ‡ï¼šy = 2*x

# print(f"è®­ç»ƒæ•°æ®:")
# print(f"X: {X.flatten()}")
# print(f"y: {y}")

# # åˆ›å»ºç®€å•æ¨¡å‹
# class LinearModel(nn.Module):
#     def __init__(self):
#         super(LinearModel, self).__init__()
#         self.linear = nn.Linear(1, 1)

#     def forward(self, x):
#         return self.linear(x).squeeze()

# model = LinearModel()
# criterion = nn.MSELoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

# print(f"\nå¼€å§‹è®­ç»ƒ...")
# for epoch in range(100):
#     # å‰å‘ä¼ æ’­
#     pred = model(X)
#     loss = criterion(pred, y)

#     # åå‘ä¼ æ’­
#     optimizer.zero_grad()
#     loss.backward()
#     optimizer.step()

#     # æ¯20è½®æ‰“å°ä¸€æ¬¡
#     if (epoch + 1) % 20 == 0:
#         print(f"Epoch {epoch+1}: Loss = {loss.item():.4f}")

# # æµ‹è¯•è®­ç»ƒç»“æœ
# test_x = torch.FloatTensor([[5]])
# pred_y = model(test_x)
# print(f"\næµ‹è¯•ï¼šx=5æ—¶ï¼Œé¢„æµ‹y={pred_y.item():.2f}ï¼ŒçœŸå®åº”è¯¥æ˜¯10")

# ğŸ’¡ è§£é‡Šï¼š
# - è¿™æ˜¯å®Œæ•´çš„è®­ç»ƒå¾ªç¯ï¼šå‰å‘â†’è®¡ç®—æŸå¤±â†’åå‘â†’æ›´æ–°å‚æ•°
# - ç»è¿‡è®­ç»ƒï¼Œæ¨¡å‹å­¦ä¼šäº† y=2*x çš„å…³ç³»

print("\nğŸ‰ æ•™ç¨‹å‡†å¤‡å®Œæˆï¼")
print("ç°åœ¨ä½ å¯ä»¥ï¼š")
print("1. é€æ­¥å–æ¶ˆæ³¨é‡Šå¹¶è¿è¡Œå„ä¸ªéƒ¨åˆ†")
print("2. è§‚å¯Ÿè¾“å‡ºï¼Œç†è§£æ¯ä¸ªæ¦‚å¿µ")
print("3. å°è¯•ä¿®æ”¹å‚æ•°ï¼Œçœ‹çœ‹ä¼šå‘ç”Ÿä»€ä¹ˆ")
print("4. æœ€åå›åˆ°åŸå§‹ä»£ç ï¼Œåº”è¯¥å°±èƒ½çœ‹æ‡‚äº†ï¼")
